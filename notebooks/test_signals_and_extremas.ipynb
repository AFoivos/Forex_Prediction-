{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb9bb29b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "FOREX DATA LOADER\n",
      "==================================================\n",
      " Available Fuctions \n",
      "1 load_csv \n",
      "2 load_from_database\n",
      "==================================================\n",
      "Data loaded successfully!\n",
      "Shape: (41476, 5)\n",
      "\n",
      "==================================================\n",
      "==================================================\n",
      "FOREX DATA CLEANER\n",
      "==================================================\n",
      " Available Fuctions \n",
      "1 remove_duplicates \n",
      "2 handle_missing_values \n",
      "3 validate_ohlc_integrity \n",
      "4 handle_outliers \n",
      "5 fast_cleaner\n",
      "==================================================\n",
      "==================================================\n",
      "Keep = first and subset = None\n",
      "Removed 0 duplicate entries\n",
      "==================================================\n",
      "OHLC DATA INTEGRITY VALIDATION\n",
      "==================================================\n",
      "No OHLC integrity violations found\n",
      "All OHLC values are consistent\n",
      "No missing values found\n",
      "==================================================\n",
      "OHLC DATA INTEGRITY VALIDATION\n",
      "==================================================\n",
      "No OHLC integrity violations found\n",
      "All OHLC values are consistent\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import argrelextrema\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "    \n",
    "from data_handle import(\n",
    "    ForexDataClean,\n",
    "    ForexDataLoad\n",
    ")\n",
    "\n",
    "from features import ForexFeauturesExtractor\n",
    "\n",
    "from plots import ForexPlotter\n",
    "from models import TimeSeriesAutoencoder\n",
    "import tensorflow as tf\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "data = ForexDataLoad(file_path = '../data/usdjpy.csv').data\n",
    "\n",
    "cleaner = ForexDataClean(data = data)\n",
    "data = cleaner.fast_cleaner()\n",
    "\n",
    "features = ForexFeauturesExtractor(\n",
    "    data = data,\n",
    "    momentum_parameters = {\n",
    "        'rsi_periods' : [4, 6, 8, 10, 12, 14]*10,\n",
    "        'stoch_fk_sk_sd_periods' : [[4, 1, 1], [6, 1, 1], [8, 2, 2], [10, 2, 2], [12, 3, 3], [14, 3, 3]]*10,\n",
    "        'williams_periods' :  [4, 6, 8, 10, 12, 14]*10,\n",
    "        'cci_periods' :  [4, 6, 8, 10, 12, 14]*10,\n",
    "        'momentum_periods' : [4, 6, 8, 10, 12, 14]*10\n",
    "    },\n",
    ")\n",
    "\n",
    "indicators_data, signals_data, extreme_data = features.extract_all_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "902f5541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       close  rsi_4_divergence  rsi_6_divergence  \\\n",
      "datetime                                                           \n",
      "2018-01-12 08:00:00  111.327                 0                 0   \n",
      "2018-01-12 09:00:00  111.368                 0                 0   \n",
      "2018-01-12 10:00:00  111.223                 0                 0   \n",
      "2018-01-12 11:00:00  111.107                 0                 0   \n",
      "2018-01-12 12:00:00  111.078                 0                 0   \n",
      "\n",
      "                     rsi_8_divergence  rsi_10_divergence  rsi_12_divergence  \\\n",
      "datetime                                                                      \n",
      "2018-01-12 08:00:00                 0                  0                  0   \n",
      "2018-01-12 09:00:00                 0                  0                  0   \n",
      "2018-01-12 10:00:00                 0                  0                  0   \n",
      "2018-01-12 11:00:00                 0                  0                  0   \n",
      "2018-01-12 12:00:00                 0                  0                  0   \n",
      "\n",
      "                     rsi_14_divergence  stoch_slowk_1_divergence  \\\n",
      "datetime                                                           \n",
      "2018-01-12 08:00:00                  0                         0   \n",
      "2018-01-12 09:00:00                  0                         0   \n",
      "2018-01-12 10:00:00                  0                         0   \n",
      "2018-01-12 11:00:00                  0                         0   \n",
      "2018-01-12 12:00:00                  0                         0   \n",
      "\n",
      "                     stoch_slowk_2_divergence  stoch_slowk_3_divergence  ...  \\\n",
      "datetime                                                                 ...   \n",
      "2018-01-12 08:00:00                         0                         0  ...   \n",
      "2018-01-12 09:00:00                         0                         0  ...   \n",
      "2018-01-12 10:00:00                         0                         0  ...   \n",
      "2018-01-12 11:00:00                         0                         0  ...   \n",
      "2018-01-12 12:00:00                         0                         0  ...   \n",
      "\n",
      "                     momentum_6_divergence  momentum_8_divergence  \\\n",
      "datetime                                                            \n",
      "2018-01-12 08:00:00                      0                      0   \n",
      "2018-01-12 09:00:00                      0                      0   \n",
      "2018-01-12 10:00:00                      0                      0   \n",
      "2018-01-12 11:00:00                      0                      0   \n",
      "2018-01-12 12:00:00                      0                      0   \n",
      "\n",
      "                     momentum_10_divergence  momentum_12_divergence  \\\n",
      "datetime                                                              \n",
      "2018-01-12 08:00:00                       0                       0   \n",
      "2018-01-12 09:00:00                       0                       0   \n",
      "2018-01-12 10:00:00                       0                       0   \n",
      "2018-01-12 11:00:00                       0                       0   \n",
      "2018-01-12 12:00:00                       0                       0   \n",
      "\n",
      "                     momentum_14_divergence  bb_20_2.0_2.0_bullish_bearish  \\\n",
      "datetime                                                                     \n",
      "2018-01-12 08:00:00                       0                              0   \n",
      "2018-01-12 09:00:00                       0                              0   \n",
      "2018-01-12 10:00:00                       0                              0   \n",
      "2018-01-12 11:00:00                       0                              0   \n",
      "2018-01-12 12:00:00                       0                              0   \n",
      "\n",
      "                     keltner_ema_20_atr_10_2.0_upper_keltner_ema_20_atr_10_2.0_lower_divergence  \\\n",
      "datetime                                                                                          \n",
      "2018-01-12 08:00:00                                                  0                            \n",
      "2018-01-12 09:00:00                                                  0                            \n",
      "2018-01-12 10:00:00                                                  0                            \n",
      "2018-01-12 11:00:00                                                  0                            \n",
      "2018-01-12 12:00:00                                                  0                            \n",
      "\n",
      "                     std_dev_20_divergence  std_dev_50_divergence  \\\n",
      "datetime                                                            \n",
      "2018-01-12 08:00:00                      0                      0   \n",
      "2018-01-12 09:00:00                      0                      0   \n",
      "2018-01-12 10:00:00                      0                      0   \n",
      "2018-01-12 11:00:00                      0                      0   \n",
      "2018-01-12 12:00:00                      0                      0   \n",
      "\n",
      "                     std_dev_100_divergence  \n",
      "datetime                                     \n",
      "2018-01-12 08:00:00                       0  \n",
      "2018-01-12 09:00:00                       0  \n",
      "2018-01-12 10:00:00                       0  \n",
      "2018-01-12 11:00:00                       0  \n",
      "2018-01-12 12:00:00                       0  \n",
      "\n",
      "[5 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "print(signals_data['divergence'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88c63406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       close  Label_p5_o1  Label_p5_o2  Label_p5_o3  \\\n",
      "datetime                                                              \n",
      "2018-01-12 08:00:00  111.327            0            0            0   \n",
      "2018-01-12 09:00:00  111.368            2            2            2   \n",
      "2018-01-12 10:00:00  111.223            0            0            0   \n",
      "2018-01-12 11:00:00  111.107            0            0            0   \n",
      "2018-01-12 12:00:00  111.078            1            1            1   \n",
      "\n",
      "                     Label_p5_o4  Label_p5_o5  Label_p5_o10  Label_p5_o20  \\\n",
      "datetime                                                                    \n",
      "2018-01-12 08:00:00            0            0             0             0   \n",
      "2018-01-12 09:00:00            2            2             0             0   \n",
      "2018-01-12 10:00:00            0            0             0             0   \n",
      "2018-01-12 11:00:00            0            0             0             0   \n",
      "2018-01-12 12:00:00            1            1             0             0   \n",
      "\n",
      "                     Label_p10_o1  Label_p10_o2  ...  Label_p50_o5  \\\n",
      "datetime                                         ...                 \n",
      "2018-01-12 08:00:00             0             0  ...             0   \n",
      "2018-01-12 09:00:00             2             2  ...             2   \n",
      "2018-01-12 10:00:00             0             0  ...             0   \n",
      "2018-01-12 11:00:00             0             0  ...             0   \n",
      "2018-01-12 12:00:00             1             1  ...             1   \n",
      "\n",
      "                     Label_p50_o10  Label_p50_o20  Label_p100_o1  \\\n",
      "datetime                                                           \n",
      "2018-01-12 08:00:00              0              0              0   \n",
      "2018-01-12 09:00:00              0              0              2   \n",
      "2018-01-12 10:00:00              0              0              0   \n",
      "2018-01-12 11:00:00              0              0              0   \n",
      "2018-01-12 12:00:00              0              0              1   \n",
      "\n",
      "                     Label_p100_o2  Label_p100_o3  Label_p100_o4  \\\n",
      "datetime                                                           \n",
      "2018-01-12 08:00:00              0              0              0   \n",
      "2018-01-12 09:00:00              2              2              2   \n",
      "2018-01-12 10:00:00              0              0              0   \n",
      "2018-01-12 11:00:00              0              0              0   \n",
      "2018-01-12 12:00:00              1              1              1   \n",
      "\n",
      "                     Label_p100_o5  Label_p100_o10  Label_p100_o20  \n",
      "datetime                                                            \n",
      "2018-01-12 08:00:00              0               0               0  \n",
      "2018-01-12 09:00:00              2               0               0  \n",
      "2018-01-12 10:00:00              0               0               0  \n",
      "2018-01-12 11:00:00              0               0               0  \n",
      "2018-01-12 12:00:00              1               0               0  \n",
      "\n",
      "[5 rows x 36 columns]\n"
     ]
    }
   ],
   "source": [
    "print(extreme_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f627ce74",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = pd.merge(\n",
    "    signals_data['divergence'],\n",
    "    extreme_data, \n",
    "    left_index=True, \n",
    "    right_index=True, \n",
    "    how='inner', \n",
    "    suffixes=('_signals', '_extreme')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c188566c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1308eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ΑΝΑΛΥΣΗ ΜΕ ΠΙΘΑΝΟΤΗΤΑ >= 80%\n",
      "============================================================\n",
      "Αναλύοντας 34 features vs 35 labels...\n",
      "Δεν βρέθηκαν features με πιθανότητα >= 80%\n",
      "Δεν βρέθηκαν κανόνες με πιθανότητα >= 80%\n",
      "\n",
      "============================================================\n",
      "ΑΝΑΛΥΣΗ ΜΕ ΠΙΘΑΝΟΤΗΤΑ >= 70%\n",
      "============================================================\n",
      "Αναλύοντας 34 features vs 35 labels...\n",
      "Δεν βρέθηκαν features με πιθανότητα >= 70%\n",
      "Δεν βρέθηκαν κανόνες με πιθανότητα >= 70%\n",
      "\n",
      "============================================================\n",
      "ΑΝΑΛΥΣΗ ΜΕ ΠΙΘΑΝΟΤΗΤΑ >= 60%\n",
      "============================================================\n",
      "Αναλύοντας 34 features vs 35 labels...\n",
      "Δεν βρέθηκαν features με πιθανότητα >= 60%\n",
      "Δεν βρέθηκαν κανόνες με πιθανότητα >= 60%\n",
      "\n",
      "============================================================\n",
      "ΑΝΑΛΥΣΗ ΜΕ ΠΙΘΑΝΟΤΗΤΑ >= 50%\n",
      "============================================================\n",
      "Αναλύοντας 34 features vs 35 labels...\n",
      "Δεν βρέθηκαν features με πιθανότητα >= 50%\n",
      "Δεν βρέθηκαν κανόνες με πιθανότητα >= 50%\n",
      "\n",
      "============================================================\n",
      "ΑΝΑΛΥΣΗ ΜΕ ΠΙΘΑΝΟΤΗΤΑ >= 40%\n",
      "============================================================\n",
      "Αναλύοντας 34 features vs 35 labels...\n",
      "Δεν βρέθηκαν features με πιθανότητα >= 40%\n",
      "Δεν βρέθηκαν κανόνες με πιθανότητα >= 40%\n",
      "\n",
      "============================================================\n",
      "ΑΝΑΛΥΣΗ ΜΕ ΠΙΘΑΝΟΤΗΤΑ >= 30%\n",
      "============================================================\n",
      "Αναλύοντας 34 features vs 35 labels...\n",
      "Δεν βρέθηκαν features με πιθανότητα >= 30%\n",
      "Δεν βρέθηκαν κανόνες με πιθανότητα >= 30%\n",
      "\n",
      "============================================================\n",
      "ΑΝΑΛΥΣΗ ΜΕ ΠΙΘΑΝΟΤΗΤΑ >= 20%\n",
      "============================================================\n",
      "Αναλύοντας 34 features vs 35 labels...\n",
      "Βρέθηκαν 130 κανόνες με πιθανότητα >= 20%\n",
      "\n",
      " TOP 10 ΚΑΝΟΝΕΣ (20%+ πιθανότητα):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>label</th>\n",
       "      <th>p(label=1|feature=1)</th>\n",
       "      <th>baseline_prob</th>\n",
       "      <th>improvement</th>\n",
       "      <th>feature_frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>cci_4_divergence</td>\n",
       "      <td>Label_p5_o1</td>\n",
       "      <td>0.283403</td>\n",
       "      <td>0.254434</td>\n",
       "      <td>0.028969</td>\n",
       "      <td>0.110791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>cci_4_divergence</td>\n",
       "      <td>Label_p10_o1</td>\n",
       "      <td>0.283403</td>\n",
       "      <td>0.254434</td>\n",
       "      <td>0.028969</td>\n",
       "      <td>0.110791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>cci_4_divergence</td>\n",
       "      <td>Label_p20_o1</td>\n",
       "      <td>0.283403</td>\n",
       "      <td>0.254434</td>\n",
       "      <td>0.028969</td>\n",
       "      <td>0.110791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>cci_4_divergence</td>\n",
       "      <td>Label_p50_o1</td>\n",
       "      <td>0.283403</td>\n",
       "      <td>0.254434</td>\n",
       "      <td>0.028969</td>\n",
       "      <td>0.110791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>cci_4_divergence</td>\n",
       "      <td>Label_p100_o1</td>\n",
       "      <td>0.283403</td>\n",
       "      <td>0.254434</td>\n",
       "      <td>0.028969</td>\n",
       "      <td>0.110791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>williams_r_4_divergence</td>\n",
       "      <td>Label_p5_o1</td>\n",
       "      <td>0.276202</td>\n",
       "      <td>0.254434</td>\n",
       "      <td>0.021769</td>\n",
       "      <td>0.115345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>williams_r_4_divergence</td>\n",
       "      <td>Label_p10_o1</td>\n",
       "      <td>0.276202</td>\n",
       "      <td>0.254434</td>\n",
       "      <td>0.021769</td>\n",
       "      <td>0.115345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>williams_r_4_divergence</td>\n",
       "      <td>Label_p20_o1</td>\n",
       "      <td>0.276202</td>\n",
       "      <td>0.254434</td>\n",
       "      <td>0.021769</td>\n",
       "      <td>0.115345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>williams_r_4_divergence</td>\n",
       "      <td>Label_p50_o1</td>\n",
       "      <td>0.276202</td>\n",
       "      <td>0.254434</td>\n",
       "      <td>0.021769</td>\n",
       "      <td>0.115345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>williams_r_4_divergence</td>\n",
       "      <td>Label_p100_o1</td>\n",
       "      <td>0.276202</td>\n",
       "      <td>0.254434</td>\n",
       "      <td>0.021769</td>\n",
       "      <td>0.115345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    feature          label  p(label=1|feature=1)  \\\n",
       "45         cci_4_divergence    Label_p5_o1              0.283403   \n",
       "46         cci_4_divergence   Label_p10_o1              0.283403   \n",
       "47         cci_4_divergence   Label_p20_o1              0.283403   \n",
       "48         cci_4_divergence   Label_p50_o1              0.283403   \n",
       "49         cci_4_divergence  Label_p100_o1              0.283403   \n",
       "15  williams_r_4_divergence    Label_p5_o1              0.276202   \n",
       "16  williams_r_4_divergence   Label_p10_o1              0.276202   \n",
       "17  williams_r_4_divergence   Label_p20_o1              0.276202   \n",
       "18  williams_r_4_divergence   Label_p50_o1              0.276202   \n",
       "19  williams_r_4_divergence  Label_p100_o1              0.276202   \n",
       "\n",
       "    baseline_prob  improvement  feature_frequency  \n",
       "45       0.254434     0.028969           0.110791  \n",
       "46       0.254434     0.028969           0.110791  \n",
       "47       0.254434     0.028969           0.110791  \n",
       "48       0.254434     0.028969           0.110791  \n",
       "49       0.254434     0.028969           0.110791  \n",
       "15       0.254434     0.021769           0.115345  \n",
       "16       0.254434     0.021769           0.115345  \n",
       "17       0.254434     0.021769           0.115345  \n",
       "18       0.254434     0.021769           0.115345  \n",
       "19       0.254434     0.021769           0.115345  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ΑΝΑΛΥΣΗ ΑΝΑ FEATURE (20%+):\n",
      "Πιο σημαντικά features:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p(label=1|feature=1)</th>\n",
       "      <th>num_labels</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bb_20_2.0_2.0_bullish_bearish</th>\n",
       "      <td>0.249411</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cci_10_divergence</th>\n",
       "      <td>0.248586</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>williams_r_6_divergence</th>\n",
       "      <td>0.271078</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>williams_r_4_divergence</th>\n",
       "      <td>0.276202</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>williams_r_14_divergence</th>\n",
       "      <td>0.262484</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>williams_r_12_divergence</th>\n",
       "      <td>0.258007</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>williams_r_10_divergence</th>\n",
       "      <td>0.253635</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stoch_slowk_3_divergence</th>\n",
       "      <td>0.222502</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stoch_slowk_2_divergence</th>\n",
       "      <td>0.229112</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stoch_slowk_1_divergence</th>\n",
       "      <td>0.271078</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               p(label=1|feature=1)  num_labels\n",
       "feature                                                        \n",
       "bb_20_2.0_2.0_bullish_bearish              0.249411           5\n",
       "cci_10_divergence                          0.248586           5\n",
       "williams_r_6_divergence                    0.271078           5\n",
       "williams_r_4_divergence                    0.276202           5\n",
       "williams_r_14_divergence                   0.262484           5\n",
       "williams_r_12_divergence                   0.258007           5\n",
       "williams_r_10_divergence                   0.253635           5\n",
       "stoch_slowk_3_divergence                   0.222502           5\n",
       "stoch_slowk_2_divergence                   0.229112           5\n",
       "stoch_slowk_1_divergence                   0.271078           5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def find_high_probability_features(merged_data, min_probability=0.7):\n",
    "\n",
    "    results = []\n",
    "    \n",
    "    feature_columns = [col for col in merged_data.columns if not col.startswith('Label_')]\n",
    "    label_columns = [col for col in merged_data.columns if col.startswith('Label_')]\n",
    "    \n",
    "    print(f\"Αναλύοντας {len(feature_columns)} features vs {len(label_columns)} labels...\")\n",
    "    \n",
    "    for feature in feature_columns:\n",
    "        for label in label_columns:\n",
    "            total_cases = len(merged_data)\n",
    "            feature_1_cases = len(merged_data[merged_data[feature] == 1])\n",
    "            \n",
    "            if feature_1_cases > 0:\n",
    "                label_1_given_feature_1 = len(\n",
    "                    merged_data[(merged_data[feature] == 1) & (merged_data[label] == 1)]\n",
    "                ) / feature_1_cases\n",
    "                \n",
    "                baseline_prob = len(merged_data[merged_data[label] == 1]) / total_cases\n",
    "                \n",
    "                if label_1_given_feature_1 >= min_probability:\n",
    "                    results.append({\n",
    "                        'feature': feature,\n",
    "                        'label': label,\n",
    "                        'p(label=1|feature=1)': label_1_given_feature_1,\n",
    "                        'baseline_prob': baseline_prob,\n",
    "                        'improvement': label_1_given_feature_1 - baseline_prob,\n",
    "                        'feature_frequency': feature_1_cases / total_cases\n",
    "                    })\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    if len(results_df) == 0:\n",
    "        print(f\"Δεν βρέθηκαν features με πιθανότητα >= {min_probability:.0%}\")\n",
    "        return pd.DataFrame()  \n",
    "    \n",
    "    sorted_results = results_df.sort_values(['p(label=1|feature=1)', 'improvement'], ascending=False)\n",
    "    \n",
    "    print(f\"Βρέθηκαν {len(sorted_results)} κανόνες με πιθανότητα >= {min_probability:.0%}\")\n",
    "    return sorted_results\n",
    "\n",
    "def comprehensive_analysis(merged_data):\n",
    "\n",
    "    thresholds = [0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1]\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"ΑΝΑΛΥΣΗ ΜΕ ΠΙΘΑΝΟΤΗΤΑ >= {threshold:.0%}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        results = find_high_probability_features(merged_data, min_probability=threshold)\n",
    "        \n",
    "        if len(results) > 0:\n",
    "            print(f\"\\n TOP 10 ΚΑΝΟΝΕΣ ({threshold:.0%}+ πιθανότητα):\")\n",
    "            display(results.head(10))\n",
    "            \n",
    "            print(f\"\\nΑΝΑΛΥΣΗ ΑΝΑ FEATURE ({threshold:.0%}+):\")\n",
    "            feature_summary = results.groupby('feature').agg({\n",
    "                'p(label=1|feature=1)': 'mean',\n",
    "                'label': 'count'\n",
    "            }).rename(columns={'label': 'num_labels'}).sort_values('num_labels', ascending=False)\n",
    "            \n",
    "            print(f\"Πιο σημαντικά features:\")\n",
    "            display(feature_summary.head(10))\n",
    "            \n",
    "            break \n",
    "        else:\n",
    "            print(f\"Δεν βρέθηκαν κανόνες με πιθανότητα >= {threshold:.0%}\")\n",
    "\n",
    "# Τρέξε την ολοκληρωμένη ανάλυση\n",
    "comprehensive_analysis(merged_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.24"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
